{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2183f50-3d39-4832-af72-42791571713d",
   "metadata": {},
   "source": [
    "# Assignment 4: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996891f9-c12d-47bb-93f5-2f25cc60709b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1) Skip-grams\n",
    "\n",
    "Tomas Mikolov's [original paper](https://arxiv.org/abs/1301.3781) for word2vec is not very specific on how to actually compute the embedding matrices.\n",
    "Xin Ron provides a much more detailed [walk-through](https://arxiv.org/pdf/1411.2738.pdf) of the math, I recommend you go through it before you continue with this assignment.\n",
    "Now, while the original implementation was in C and estimates the matrices directly, in this assignment, we want to use PyTorch (and autograd) to train the matrices.\n",
    "There are plenty of example implementations and blog posts out there that show how to do it, I particularly recommend [Mateusz Bednarski's](https://towardsdatascience.com/implementing-word2vec-in-pytorch-skip-gram-model-e6bae040d2fb) version. Familiarize yourself with skip-grams and how to train them using pytorch.\n",
    "\n",
    "### Data\n",
    "\n",
    "Download the `theses.csv` data set from the `Supplemental Materials` in the `Files` section of our Microsoft Teams group.\n",
    "This dataset consists of approx. 3,000 theses topics chosen by students in the past.\n",
    "Here are some examples of the file content:\n",
    "\n",
    "```\n",
    "27.10.94;14.07.95;1995;intern;Diplom;DE;Monte Carlo-Simulation für ein gekoppeltes Round-Robin-System;\n",
    "04.11.94;14.03.95;1995;intern;Diplom;DE;Implementierung eines Testüberdeckungsgrad-Analysators für RAS;\n",
    "01.11.20;01.04.21;2021;intern;Bachelor;DE;Landessprachenerkennung mittels X-Vektoren und Meta-Klassifikation;\n",
    "```\n",
    "\n",
    "### Basic Setup\n",
    "\n",
    "For the upcoming assignments on Neural Networks, we'll be heavily using [PyTorch](https://pytorch.org) as go-to Deep Learning library.\n",
    "If you're not already familiar with PyTorch, now's the time to get started with it.\n",
    "Head over to the [Basics](https://pytorch.org/tutorials/beginner/basics/intro.html) and gain some understanding about the essentials.\n",
    "Before starting this assignment, make sure you've got PyTorch installed in your working environment. \n",
    "It's a quick setup, and you'll find all the instructions you need on the PyTorch website.\n",
    "As always, you can use [NumPy](https://numpy.org) and [Pandas](https://pandas.pydata.org) for data handling etc.\n",
    "\n",
    "*In this Jupyter Notebook, we will provide the steps to solve this task and give hints via functions & comments. However, code modifications (e.g., function naming, arguments) and implementation of additional helper functions & classes are allowed. The code aims to help you get started.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ffb0527-90ea-4f0a-ab0c-40817df51dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "from typing import TypedDict, Iterator, Iterable, Optional\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "from math import floor, ceil\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf666267-390d-402a-aae9-e3588b51c262",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "1.1 Spend some time on preparing the dataset. It may be helpful to lower-case the data and to filter for German titles. The format of the CSV-file should be:\n",
    "\n",
    "```\n",
    "Anmeldedatum;Abgabedatum;JahrAkademisch;Art;Grad;Sprache;Titel;Abstract\n",
    "```\n",
    "\n",
    "1.2 Create the vocabulary from the prepared dataset. You'll need it for the initialization of the matrices and to map tokens to indices.\n",
    "\n",
    "1.3 Generate the training pairs with center word and context word. Which window size do you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c9e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"data/theses2022.csv\"\n",
    "\n",
    "@dataclass\n",
    "class Thesis:\n",
    "    registration_date: str\n",
    "    due_date: str\n",
    "    year_academic: int\n",
    "    type: str\n",
    "    degree: str\n",
    "    language: str\n",
    "    title: str\n",
    "    abstract: str\n",
    "\n",
    "class _Thesis(TypedDict):\n",
    "    Anmeldedatum: str\n",
    "    Abgabedatum: str\n",
    "    JahrAkademisch: str\n",
    "    Art: str\n",
    "    Grad: str\n",
    "    Sprache: str\n",
    "    Titel: str\n",
    "    Abstract: str\n",
    "\n",
    "def to_thesis(thesis: _Thesis) -> Thesis:\n",
    "    return Thesis(\n",
    "        registration_date=thesis[\"Anmeldedatum\"],\n",
    "        due_date=thesis[\"Abgabedatum\"],\n",
    "        year_academic=int(thesis[\"JahrAkademisch\"]),\n",
    "        type=thesis[\"JahrAkademisch\"],\n",
    "        degree=thesis[\"Grad\"],\n",
    "        language=thesis[\"Sprache\"],\n",
    "        title=thesis[\"Titel\"],\n",
    "        abstract=thesis[\"Abstract\"]\n",
    "    )\n",
    "\n",
    "def load_theses_dataset(filepath) -> pd.DataFrame:\n",
    "    \"\"\"Loads all theses instances and returns them as a dataframe.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    lists = {key: [] for key in Thesis.__dataclass_fields__.keys()}\n",
    "    with open(filepath, encoding=\"utf-8-sig\") as fp:\n",
    "        theses = map(to_thesis, csv.DictReader(fp.readlines(), delimiter=\";\")) # type: ignore\n",
    "        for thesis in theses:\n",
    "            for key in lists:\n",
    "                lists[key].append(thesis.__dict__[key])\n",
    "    return pd.DataFrame(lists)\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "dataset = load_theses_dataset(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa699c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> Iterator[str]:\n",
    "    for s in text.split():\n",
    "        m = re.match(r\"^([@#]?\\w+)[,\\.?!]?$\", s)\n",
    "        if m is not None:\n",
    "            yield m.group(1)\n",
    "\n",
    "def preprocess(dataframe: pd.DataFrame) -> list[list[str]]:\n",
    "    \"\"\"Preprocesses and tokenizes the given theses titles for further use.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    l = []\n",
    "    for i in range(len(dataframe)):\n",
    "        if dataframe[\"language\"][i] == \"DE\":\n",
    "            l.append(list(tokenize(dataframe[\"title\"][i])))\n",
    "            l.append(list(tokenize(dataframe[\"abstract\"][i])))\n",
    "    return l\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3acde311",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVE_SAMPLING_RATIO = 3\n",
    "\n",
    "def word_frequencies(word2idx: dict[str, int], data: Iterable[str]) -> np.ndarray:\n",
    "    counts = np.zeros(len(word2idx), np.int32)\n",
    "    total = 0\n",
    "    for w in data:\n",
    "        counts[word2idx[w]] += 1\n",
    "        total += 1\n",
    "    return counts / total\n",
    "\n",
    "def draw_idx(word_frequencies: np.ndarray) -> int:\n",
    "    return np.random.choice(word_frequencies.shape[0], p=word_frequencies)\n",
    "\n",
    "def create_training_pairs(data: list[list[str]], word2idx: dict[str, int], window_size: int) -> list[tuple[int, list[int], list[int]]]:\n",
    "    \"\"\"Creates training pairs based on skip-grams for further use.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    data = list(filter(lambda l: len(l) > 2 * window_size, data))\n",
    "    freqs = word_frequencies(word2idx, (w for l in data for w in l))\n",
    "    negative_count = NEGATIVE_SAMPLING_RATIO * window_size\n",
    "    result = []\n",
    "    for l in data:\n",
    "        for i in range(window_size, len(l) - window_size):\n",
    "            center = word2idx[l[i]]\n",
    "            positive = []\n",
    "            for j in range(i - window_size, i):\n",
    "                positive.append(word2idx[l[j]])\n",
    "            for j in range(i + 1, i + window_size + 1):\n",
    "                positive.append(word2idx[l[j]])\n",
    "            pos_set = set(positive)\n",
    "            neg_set = set()\n",
    "            while len(neg_set) < negative_count:\n",
    "                neg = draw_idx(freqs)\n",
    "                if not neg in pos_set:\n",
    "                    neg_set.add(neg)\n",
    "            result.append((center, positive, list(neg_set)))\n",
    "    return result\n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "299d6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = load_theses_dataset(DATASET_PATH)\n",
    "tokenized_data = preprocess(dataframe)\n",
    "vocabulary = {w for l in tokenized_data for w in l}\n",
    "word2idx = {w: i for i, w in enumerate(vocabulary)}\n",
    "idx2word = list(vocabulary)\n",
    "training_pairs = create_training_pairs(tokenized_data, word2idx, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb8bb6",
   "metadata": {},
   "source": [
    "### Train and Analyze\n",
    "\n",
    "2.1 Implement and train the word2vec model with your training data.\n",
    "\n",
    "2.2 Implement a method to find the top-k similar words for a given word (token).\n",
    "\n",
    "2.3 Analyze: What are the most similar words to \"Konzeption\", \"Cloud\" and \"virtuelle\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a65b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 13.329922548167188\n",
      "training epoch 2/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 10.964425131694831\n",
      "training epoch 3/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 10.181577068898774\n",
      "training epoch 4/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 9.719602912956912\n",
      "training epoch 5/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 9.395797439333917\n",
      "training epoch 6/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 9.1462579030897\n",
      "training epoch 7/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 8.939724311963813\n",
      "training epoch 8/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 8.775527920041766\n",
      "training epoch 9/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 8.627199096534088\n",
      "training epoch 10/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 8.500983898876278\n",
      "training epoch 11/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 8.388550286724627\n",
      "training epoch 12/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 8.291289253869259\n",
      "training epoch 13/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 8.207251616366687\n",
      "training epoch 14/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 8.128340073734229\n",
      "training epoch 15/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 8.054592173388116\n",
      "training epoch 16/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.984684061198094\n",
      "training epoch 17/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.923591976727368\n",
      "training epoch 18/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.868437487010477\n",
      "training epoch 19/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.8159471330361905\n",
      "training epoch 20/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.768659027478167\n",
      "training epoch 21/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.725681140092623\n",
      "training epoch 22/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.684250244527503\n",
      "training epoch 23/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.6439464989249295\n",
      "training epoch 24/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.606316890945352\n",
      "training epoch 25/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.571764102028917\n",
      "training epoch 26/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.538409264293076\n",
      "training epoch 27/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.505396902496188\n",
      "training epoch 28/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.474280841997952\n",
      "training epoch 29/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.445324201750261\n",
      "training epoch 30/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.417288588853543\n",
      "training epoch 31/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.3911235808286175\n",
      "training epoch 32/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.366193973641099\n",
      "training epoch 33/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.343818249333256\n",
      "training epoch 34/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.318730345469135\n",
      "training epoch 35/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.296759281969642\n",
      "training epoch 36/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.277613943509733\n",
      "training epoch 37/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.260247258089621\n",
      "training epoch 38/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.237619039666562\n",
      "training epoch 39/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.219171113510298\n",
      "training epoch 40/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.202458330173139\n",
      "training epoch 41/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.187560390100094\n",
      "training epoch 42/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.171207067100666\n",
      "training epoch 43/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.155910005486258\n",
      "training epoch 44/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.141407990793626\n",
      "training epoch 45/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.128018910908257\n",
      "training epoch 46/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.115103327721\n",
      "training epoch 47/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.103787868337517\n",
      "training epoch 48/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.092578081164262\n",
      "training epoch 49/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.081058713316008\n",
      "training epoch 50/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.072436118203915\n",
      "training epoch 51/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.061294389005056\n",
      "training epoch 52/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.053530193337178\n",
      "training epoch 53/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.043458535861033\n",
      "training epoch 54/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.03454216667974\n",
      "training epoch 55/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.025743928834422\n",
      "training epoch 56/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.017383696338733\n",
      "training epoch 57/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.01021981213319\n",
      "training epoch 58/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 7.006137988299554\n",
      "training epoch 59/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.998896716595216\n",
      "training epoch 60/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.998561081475494\n",
      "training epoch 61/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.99404082277479\n",
      "training epoch 62/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.9820751280665005\n",
      "training epoch 63/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.976527462348813\n",
      "training epoch 64/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.97354334963317\n",
      "training epoch 65/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.9680559577962695\n",
      "training epoch 66/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.962858849289373\n",
      "training epoch 67/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.960386020146643\n",
      "training epoch 68/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.957390652878074\n",
      "training epoch 69/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.954986552505742\n",
      "training epoch 70/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.944910453996066\n",
      "training epoch 71/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.943002210968583\n",
      "training epoch 72/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.938926367099309\n",
      "training epoch 73/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.939365846380153\n",
      "training epoch 74/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.932989367481927\n",
      "training epoch 75/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.929921873523209\n",
      "training epoch 76/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.927219967025707\n",
      "training epoch 77/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.924335419676686\n",
      "training epoch 78/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.923419332556272\n",
      "training epoch 79/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.922867936682415\n",
      "training epoch 80/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.918908474359544\n",
      "training epoch 81/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.914471701941287\n",
      "training epoch 82/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.913110760852061\n",
      "training epoch 83/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.910074659366254\n",
      "training epoch 84/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.908493788967736\n",
      "training epoch 85/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.905472632972859\n",
      "training epoch 86/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.902507553963781\n",
      "training epoch 87/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.900383692141317\n",
      "training epoch 88/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.900324124936319\n",
      "training epoch 89/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.898561820079092\n",
      "training epoch 90/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.896607624665472\n",
      "training epoch 91/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.897891794972227\n",
      "training epoch 92/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.895133867648592\n",
      "training epoch 93/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.891976546565215\n",
      "training epoch 94/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.890710763868875\n",
      "training epoch 95/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.889695532839327\n",
      "training epoch 96/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.889382444265235\n",
      "training epoch 97/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.891295663923057\n",
      "training epoch 98/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.884454967931417\n",
      "training epoch 99/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.883445213769228\n",
      "training epoch 100/100...\n",
      "    batch 1834/1834\n",
      "    average loss: 6.883239663154244\n"
     ]
    }
   ],
   "source": [
    "### TODO: 2.1 Implement and train the word2vec model.\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "@dataclass\n",
    "class Batch:\n",
    "    x_in: torch.Tensor\n",
    "    x_out: torch.Tensor\n",
    "    p: torch.nn.Parameter\n",
    "    o: torch.nn.Parameter\n",
    "    y: torch.Tensor\n",
    "    p_idcs: list[int]\n",
    "    o_idcs: list[int]\n",
    "\n",
    "    def __del__(self):\n",
    "        del self.x_in\n",
    "        del self.x_out\n",
    "        del self.p\n",
    "        del self.o\n",
    "        del self.y\n",
    "        del self.p_idcs\n",
    "        del self.o_idcs\n",
    "        \n",
    "\n",
    "class BatchAllocator(Iterable[Batch]):\n",
    "    @property\n",
    "    def batch_size(self) -> int:\n",
    "        return self.__batch_size\n",
    "    \n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return self.__device\n",
    "\n",
    "    def __init__(self, batch_size: int, data_list: list[tuple[int, list[int], list[int]]], device: torch.device):\n",
    "        self.__batch_size = batch_size\n",
    "        self.__data_list = data_list\n",
    "        self.__device = device\n",
    "        self.__samples_per_input = len(data_list[0][1]) + len(data_list[0][2])\n",
    "        self.P = torch.tensor(0)\n",
    "        self.O = torch.tensor(0)\n",
    "\n",
    "    def __iter__(self) -> Iterator[Batch]:\n",
    "        for idcs in self.__idcs():\n",
    "            yield self.__allocate_batch(idcs)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return ceil(len(self.__data_list) / self.batch_size)    \n",
    "\n",
    "    def __allocate_batch(self, idcs: tuple[int, int]) -> Batch:\n",
    "        i, j = idcs\n",
    "        size = j - i\n",
    "        p_idx_set = set()\n",
    "        o_idx_set = set()\n",
    "        for center, positive, negative in (self.__data_list[k] for k in range(i, j)):\n",
    "            p_idx_set.add(center)\n",
    "            for l in positive:\n",
    "                o_idx_set.add(l)\n",
    "            for l in negative:\n",
    "                o_idx_set.add(l)\n",
    "        p_idcs = list(p_idx_set)\n",
    "        o_idcs = list(o_idx_set)\n",
    "        x_in = torch.zeros((size, 1, len(p_idcs)), dtype=torch.float32,)\n",
    "        p = torch.empty((1, len(p_idcs), self.P.shape[1]), dtype=torch.float32)\n",
    "        o = torch.empty((1, self.O.shape[1], len(o_idcs)), dtype=torch.float32)\n",
    "        x_out = torch.zeros((size, len(o_idcs), self.__samples_per_input), dtype=torch.float32)\n",
    "        y = torch.hstack((\n",
    "            torch.ones((size, len(self.__data_list[0][1])), dtype=torch.float32, device=self.device),\n",
    "            torch.zeros((size, len(self.__data_list[1][2])), dtype=torch.float32, device=self.device)\n",
    "        ))\n",
    "        for k in range(size):\n",
    "            center, positive, negative = self.__data_list[i + k]\n",
    "            x_in[k, 0, p_idcs.index(center)] = 1\n",
    "            for l in range(len(positive)):\n",
    "                x_out[k, o_idcs.index(positive[l]), l] = 1\n",
    "                y[k, l] = 1\n",
    "            for l in range(len(negative)):\n",
    "                x_out[k, o_idcs.index(negative[l]), l + len(positive)] = 1\n",
    "        for row, p_idx in enumerate(p_idcs):\n",
    "            p[0, row, :] = self.P[p_idx, :]\n",
    "        for col, o_idx in enumerate(o_idcs):\n",
    "            o[0, :, col] = self.O[o_idx, :]\n",
    "        return Batch(x_in.to(self.device), x_out.to(self.device), torch.nn.Parameter(p.to(self.device)), torch.nn.Parameter(o.to(self.device)), y, p_idcs, o_idcs) # type: ignore\n",
    "\n",
    "    def __idcs(self) -> Iterator[tuple[int, int]]:\n",
    "        i = 0\n",
    "        for _ in range(floor(len(self.__data_list) / self.batch_size)):\n",
    "            j = i + self.batch_size\n",
    "            yield i, j\n",
    "            i = j\n",
    "        if i < len(self.__data_list):\n",
    "            yield i, len(self.__data_list)\n",
    "\n",
    "def word2vec(voc_size: int, data_list: list[tuple[int, list[int], list[int]]], dim: int, batch_size: int, epochs: int, lr: float, device: Optional[torch.device] = None) -> torch.Tensor:\n",
    "    if device == None:\n",
    "        device = torch.device(\"cpu\")\n",
    "    P = torch.rand((voc_size, dim))\n",
    "    O = torch.rand((voc_size, dim))\n",
    "    allocator = BatchAllocator(batch_size, data_list, device)\n",
    "    allocator.P = P\n",
    "    allocator.O = O\n",
    "    batch_count = len(allocator)\n",
    "    for e in range(1, epochs + 1):\n",
    "        print(f\"training epoch {e}/{epochs}...\")\n",
    "        running_loss = 0\n",
    "        for k, batch in enumerate(allocator):\n",
    "            print(f\"\\r    batch {k + 1}/{batch_count}\", end=\"\")\n",
    "            opt = torch.optim.SGD([batch.p, batch.o], lr)\n",
    "            opt.zero_grad()\n",
    "            logits = (batch.x_in @ batch.p @ batch.o @ batch.x_out).flatten(end_dim=1)\n",
    "            loss = torch.nn.functional.cross_entropy(logits, batch.y)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            with torch.no_grad():\n",
    "                for i, j in enumerate(batch.p_idcs):\n",
    "                    P[j, :] = batch.p[0, i, :]\n",
    "                for i, j in enumerate(batch.o_idcs):\n",
    "                    O[j, :] = batch.o[0, :, i]\n",
    "            del opt\n",
    "            del loss\n",
    "            del logits\n",
    "            del batch\n",
    "        print()\n",
    "        print(f\"    average loss: {running_loss / batch_count}\")\n",
    "    return P + O\n",
    "\n",
    "M = word2vec(len(idx2word), training_pairs, 300, 64, 100, 0.3)     \n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02549c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 2.2 Implement a method to find the top-k similar words.\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "def nearest_neighbours(query: str, word2idx: dict[str, int], V: list[str], M: torch.Tensor, k: int):\n",
    "    query_idx = word2idx[query]\n",
    "    scores = M[query_idx, :] @ M.T\n",
    "    top_idcs = [-1 for _ in range(k)]\n",
    "    for i in range(scores.shape[0]):\n",
    "        if not i == query_idx:\n",
    "            for j in range(k):\n",
    "                if top_idcs[j] == -1 or scores[top_idcs[j]] < scores[i]:\n",
    "                    top_idcs.insert(j, i)\n",
    "                    del top_idcs[-1]\n",
    "                    break\n",
    "    count = k\n",
    "    while top_idcs[k-1] == -1:\n",
    "        count -= 1\n",
    "    result = []\n",
    "    for j in range(count):\n",
    "        i = top_idcs[j]\n",
    "        result.append((idx2word[i], scores[i].item()))\n",
    "    return result\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b5fa1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hauptteile', 229.1881866455078), ('integrierten', 223.59689331054688), ('Nutzweranalyse', 223.5181427001953), ('zusteuert', 223.23220825195312), ('konkurrierende', 222.9911346435547)]\n",
      "[('Dann', 315.9914855957031), ('schafft', 314.2419128417969), ('Beratungsforums', 313.81414794921875), ('Testdatensätze', 313.0927429199219), ('vielversprechendes', 313.0432434082031)]\n",
      "[('Auswertungstool', 310.2977294921875), ('allgemeinere', 309.85821533203125), ('Beratungsforums', 309.698974609375), ('unnatürlich', 309.59332275390625), ('Nächstes', 308.993408203125)]\n"
     ]
    }
   ],
   "source": [
    "### TODO: 2.3 Find the most similar words for \"Konzeption\", \"Cloud\" and \"virtuelle\".\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "print(nearest_neighbours(\"Konzeption\", word2idx, idx2word, M, 5))\n",
    "print(nearest_neighbours(\"Cloud\", word2idx, idx2word, M, 5))\n",
    "print(nearest_neighbours(\"virtuelle\", word2idx, idx2word, M, 5))\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe48a9b",
   "metadata": {},
   "source": [
    "### Play with the Embeddings\n",
    "\n",
    "3.1 Use the computed embeddings: Can you identify the most similar theses for some examples?\n",
    "\n",
    "3.2 Visualize the embeddings for a subset of theses using [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). You can use [Scikit-Learn](https://scikit-learn.org/stable/) and [Matplotlib](https://matplotlib.org) or [Seaborn](https://seaborn.pydata.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3eb891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: 3.1 Compute the embeddings for the theses and transform with TSNE.\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "SAMPLE_COUNT = 100\n",
    "\n",
    "def thesis_embedding(thesis: Thesis, word2idx: dict[str, int], M: torch.Tensor) -> torch.Tensor:\n",
    "    total = torch.zeros(M.shape[1], dtype=M.dtype)\n",
    "    for i in map(lambda t: word2idx[t], tokenize(thesis.title)):\n",
    "        total += M[i, :]\n",
    "    for i in map(lambda t: word2idx[t], tokenize(thesis.abstract)):\n",
    "        total += M[i, :]\n",
    "    return total / total.norm()\n",
    "\n",
    "embedding_list = []\n",
    "for d in dataframe.to_dict(\"records\"):\n",
    "    if len(embedding_list) == SAMPLE_COUNT:\n",
    "        break\n",
    "    if d[\"language\"] == \"DE\":\n",
    "        embedding_list.append(thesis_embedding(Thesis(**d), word2idx, M).numpy()) # type: ignore\n",
    "embeddings = np.array(embedding_list)\n",
    "\n",
    "tsne = TSNE(2)\n",
    "transformed = tsne.fit_transform(embeddings)\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95a5251a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbfe86ddba0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TODO: 3.2 Visualize the samples in the 2D space.\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "plt.scatter(transformed[:, 0], transformed[:, 1])\n",
    "\n",
    "### END YOUR CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
