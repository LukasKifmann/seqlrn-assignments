{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2183f50-3d39-4832-af72-42791571713d",
   "metadata": {},
   "source": [
    "# Assignment 2: POTUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996891f9-c12d-47bb-93f5-2f25cc60709b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1) President of the United States (Trump vs. Obama)\n",
    "\n",
    "Surely, you're aware that the 45th President of the United States (@POTUS45) was an active user of Twitter, until (permanently) banned on Jan 8, 2021.\n",
    "You can still enjoy his greatness at the [Trump Twitter Archive](https://www.thetrumparchive.com/). We will be using original tweets only, so make sure to remove all retweets.\n",
    "Another fan of Twitter was Barack Obama (@POTUS43 and @POTUS44), who used the platform in a rather professional way.\n",
    "Please also consider the POTUS Tweets of Joe Biden; we will be using those for testing.\n",
    "\n",
    "### Data\n",
    "\n",
    "There are multiple ways to get the data, but the easiest way is to download the files from the `Supplemental Materials` in the `Files` section of our Microsoft Teams group. \n",
    "Another way is to directly use the data from [Trump Twitter Archive](https://www.thetrumparchive.com/), [Obama Kaggle](https://www.kaggle.com/jayrav13/obama-white-house), and [Biden Kaggle](https://www.kaggle.com/rohanrao/joe-biden-tweets).\n",
    "Before you get started, please download the files; you can put them into the data folder.\n",
    "\n",
    "### N-gram Models\n",
    "\n",
    "In this assignment, you will be doing some Twitter-related preprocessing and training n-gram models to be able to distinguish between Tweets of Trump, Obama, and Biden.\n",
    "We will be using [NLTK](https://www.nltk.org), more specifically it's [`lm`](https://www.nltk.org/api/nltk.lm.html) module. \n",
    "Install the NLTK package within your working environment.\n",
    "You can use some of the NLTK functions, but you have to implement the functions for likelihoods and perplexity from scratch.\n",
    "\n",
    "*In this Jupyter Notebook, we will provide the steps to solve this task and give hints via functions & comments. However, code modifications (e.g., function naming, arguments) and implementation of additional helper functions & classes are allowed. The code aims to help you get started.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5ffb0527-90ea-4f0a-ab0c-40817df51dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import nltk\n",
    "from nltk import lm\n",
    "from typing import TypedDict, Iterable, Iterator, Collection, Callable\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "from typing import Optional\n",
    "import random\n",
    "from functools import reduce\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf666267-390d-402a-aae9-e3588b51c262",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "1.1 Prepare all the Tweets. Since the `lm` modules will work on tokenized data, implement a tokenization method that strips unnecessary tokens but retains special words such as mentions (@...) and hashtags (#...).\n",
    "\n",
    "1.2 Partition into training and test sets; select about 100 tweets each, which we will be testing on later. As with any Machine Learning task, training and test must not overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c2ae5b5d-fccd-4092-af20-d8e8b4a65ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice: ignore retweets\n",
    "\n",
    "TRUMP = \"trump\"\n",
    "OBAMA = \"obama\"\n",
    "BIDEN = \"biden\"\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "TRUMP_TWEETS_FILE = f\"{DATA_DIR}/tweets_01-08-2021.json\"\n",
    "OBAMA_TWEETS_FILE = f\"{DATA_DIR}/Tweets-BarackObama.csv\"\n",
    "BIDEN_TWEETS_FILE = f\"{DATA_DIR}/JoeBidenTweets.csv\"\n",
    "\n",
    "@dataclass\n",
    "class Tweet:\n",
    "    author: str\n",
    "    text: str\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_TrumpTweets(trump_tweets: Iterable[\"TrumpTweet\"]) -> list[\"Tweet\"]:\n",
    "        return list(map(\n",
    "            lambda t: Tweet(author=TRUMP, text=t[\"text\"]),\n",
    "            filter(lambda t: t[\"isRetweet\"] == \"f\", trump_tweets)\n",
    "        ))\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_ObamaTweets(obama_tweets: Iterable[\"ObamaTweet\"]) -> list[\"Tweet\"]:\n",
    "        return list(map(\n",
    "            lambda t: Tweet(author=OBAMA, text=t[\"tweet\"]),\n",
    "            obama_tweets\n",
    "        ))\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_BidenTweets(biden_tweets: Iterable[\"BidenTweet\"]) -> list[\"Tweet\"]:\n",
    "        return list(map(\n",
    "            lambda t: Tweet(author=BIDEN, text=t[\"Tweet-text\"]),\n",
    "            biden_tweets\n",
    "        ))\n",
    "\n",
    "class TrumpTweet(TypedDict):\n",
    "    id: int\n",
    "    text: str\n",
    "    isRetweet: str\n",
    "    isDeleted: str\n",
    "    device: str\n",
    "    favorites: int\n",
    "    retweets: int\n",
    "    date: str\n",
    "    isFlagged: str\n",
    "\n",
    "class ObamaTweet(TypedDict):\n",
    "    id: str\n",
    "    timestamp: str\n",
    "    url: str\n",
    "    tweet: str\n",
    "    replies: str\n",
    "    retweets: str\n",
    "    quotes: str\n",
    "    likes: str\n",
    "\n",
    "BidenTweet = TypedDict(\n",
    "    \"BidenTweet\",\n",
    "    {\n",
    "        \"Date\": str,\n",
    "        \"Username\": str,\n",
    "        \"Tweet-text\": str,\n",
    "        \"Tweet Link\": str,\n",
    "        \"Retweets\": str,\n",
    "        \"Likes\": str,\n",
    "        \"TweetImageUrl\": str,\n",
    "        \"Image\": str\n",
    "    }\n",
    ")\n",
    "\n",
    "def load_trump_tweets(filepath) -> list[Tweet]:\n",
    "    \"\"\"Loads all Trump tweets and returns them as a list.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    with open(filepath) as fp:\n",
    "        return Tweet.from_TrumpTweets(json.load(fp))\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def load_obama_tweets(filepath) -> list[Tweet]:\n",
    "    \"\"\"Loads all Obama tweets and returns them as a list.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    with open(filepath) as fp:\n",
    "        return Tweet.from_ObamaTweets(csv.DictReader(fp.readlines(), ObamaTweet.__required_keys__)) # type: ignore\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "\n",
    "def load_biden_tweets(filepath) -> list[Tweet]:\n",
    "    \"\"\"Loads all Biden tweets and returns them as a list.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    with open(filepath) as fp:\n",
    "        return Tweet.from_BidenTweets(csv.DictReader(fp.readlines(), BidenTweet.__required_keys__)) # type: ignore\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f25e8c56-3837-440b-bebe-1916ebede6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice: think about start and end tokens\n",
    "\n",
    "NUM_TEST = 100\n",
    "\n",
    "def tokenize(text: str) -> Iterator[str]:\n",
    "    \"\"\"Tokenizes a single Tweet.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    yield \"<s>\"\n",
    "    for s in text.split():\n",
    "        m = re.match(r\"^((?:[#@]?\\w+)|(?:\\w+:\\/\\/\\w+(?:\\.\\w+)*(?::\\d*)?(?:(?:\\/[^,.?!]*)*\\/?)))[,\\.!?]?$\", s)\n",
    "        if m is not None:\n",
    "            if m.group(1) is None:\n",
    "                print(m)\n",
    "                print(m.group(1))\n",
    "            yield m.group(1)\n",
    "    yield \"</s>\"\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "\n",
    "def split_and_tokenize(data: list[Tweet], num_test=NUM_TEST) -> list[list[str]]:\n",
    "    \"\"\"Splits and tokenizes the given list of Twitter tweets.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    return [list(tokenize(tweet.text)) for tweet in data]\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2598cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_COUNT = 100\n",
    "\n",
    "trump_tweets = split_and_tokenize(load_trump_tweets(TRUMP_TWEETS_FILE))\n",
    "obama_tweets = split_and_tokenize(load_obama_tweets(OBAMA_TWEETS_FILE))\n",
    "biden_tweets = split_and_tokenize(load_biden_tweets(BIDEN_TWEETS_FILE))\n",
    "\n",
    "data_train = {}\n",
    "data_test = {}\n",
    "\n",
    "data_train[TRUMP], data_test[TRUMP] = train_test_split(trump_tweets, test_size=TEST_COUNT / len(trump_tweets))\n",
    "data_train[OBAMA], data_test[OBAMA] = train_test_split(obama_tweets, test_size=TEST_COUNT / len(obama_tweets))\n",
    "data_train[BIDEN], data_test[BIDEN] = train_test_split(biden_tweets, test_size=TEST_COUNT / len(biden_tweets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c32c33-1a19-42ac-93d0-fcf66fbeaf5f",
   "metadata": {},
   "source": [
    "### Train N-gram Models\n",
    "\n",
    "2.1 Train n-gram models with n = [1, ..., 5] for Obama, Trump, and Biden.\n",
    "\n",
    "2.2 Also train a joint model, that will serve as background model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0828bda0-cef2-428b-a238-7f07f2c25425",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKGROUND_MODEL_KEY = \"background\"\n",
    "\n",
    "class NGramModel:\n",
    "    @property\n",
    "    def n(self):\n",
    "        return self.__n\n",
    "\n",
    "    @property\n",
    "    def V(self):\n",
    "        return self.__V\n",
    "\n",
    "    def __init__(self, n: int, data: list[list[str]], V: Optional[set[str]] = None):\n",
    "        assert n > 1\n",
    "        self.__n = n\n",
    "        if V is None: \n",
    "            self.__V = set(s for l in data for s in l)\n",
    "        else:\n",
    "            self.__V = V\n",
    "        if n > 2:\n",
    "            self.__n_minus_1_gram_model = NGramModel(n-1, [l[:n-1] for l in data], self.V)\n",
    "        n_gram_counts = dict()\n",
    "        n_minus_1_gram_counts = dict()\n",
    "        for l in data:\n",
    "            for i in range(len(l) - n + 1):\n",
    "                n_gram = tuple(l[i: i + n])\n",
    "                n_minus_1_gram = n_gram[:-1]\n",
    "                if not n_minus_1_gram in n_minus_1_gram_counts:\n",
    "                    n_minus_1_gram_counts[n_minus_1_gram] = len(self.V)\n",
    "                    n_gram_counts[n_minus_1_gram] = {n_gram: 2}\n",
    "                else:\n",
    "                    n_minus_1_gram_counts[n_minus_1_gram] += 1\n",
    "                    if not n_gram in n_gram_counts[n_minus_1_gram]:\n",
    "                        n_gram_counts[n_minus_1_gram][n_gram] = 2\n",
    "                    else:\n",
    "                        n_gram_counts[n_minus_1_gram][n_gram] += 1\n",
    "        self.__conditionals = {\n",
    "            n_minus_1_gram: {\n",
    "                n_gram: n_gram_counts[n_minus_1_gram][n_gram] / n_minus_1_gram_counts[n_minus_1_gram]\n",
    "                for n_gram in n_gram_counts[n_minus_1_gram]\n",
    "            }\n",
    "            for n_minus_1_gram in n_minus_1_gram_counts\n",
    "        }\n",
    "        self.__n_minus_1_gram_counts = n_minus_1_gram_counts\n",
    "        \n",
    "    def conditional(self, n_gram: tuple[str,...]) -> float:\n",
    "        l = len(n_gram)\n",
    "        assert 1 < l and l <= self.n\n",
    "        if n_gram[-1] == \"<s>\":\n",
    "            return 0\n",
    "        elif l == self.n:\n",
    "            n_minus_1_gram = n_gram[:-1]\n",
    "            if n_minus_1_gram in self.__conditionals:\n",
    "                if n_gram in self.__conditionals[n_minus_1_gram]:\n",
    "                    return self.__conditionals[n_minus_1_gram][n_gram]\n",
    "                else:\n",
    "                    return 1 / self.__n_minus_1_gram_counts[n_minus_1_gram]\n",
    "            else:\n",
    "                return 1 / (len(self.V) - 1)\n",
    "        else:\n",
    "            return self.__n_minus_1_gram_model.conditional(n_gram)\n",
    "        \n",
    "    def continuations(self, n_minus_1_gram: tuple[str,...]) -> Iterator[tuple[str, float]]:\n",
    "        l = len(n_minus_1_gram)\n",
    "        assert 0 < l and l < self.n\n",
    "        if l == self.n - 1:\n",
    "            return ((t, self.conditional(n_minus_1_gram + (t,))) for t in self.V)\n",
    "        else:\n",
    "            return self.__n_minus_1_gram_model.continuations(n_minus_1_gram)\n",
    "\n",
    "def build_n_gram_models(n, data: dict[str, list[list[str]]]):\n",
    "    \"\"\"\n",
    "    To predict the first few words of the Tweet, we need the smaller n-grams as\n",
    "    well. This method does calculate all n-grams up to the given n.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    d = {k: NGramModel(n, l) for k, l in data.items()}\n",
    "    d[BACKGROUND_MODEL_KEY] = NGramModel(n, reduce(lambda a, b: a + b, data.values(), []))\n",
    "    return d\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def get_suggestion(prev: Collection[str], n_gram_model: NGramModel) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Gets the next random word for the given n_grams.\n",
    "    The size of the previous tokens must be exactly one less than the n-value\n",
    "    of the n-gram, or it will not be able to make a prediction.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    sum = 0\n",
    "    r = random.random()\n",
    "    for cont, cond in n_gram_model.continuations(tuple(prev)):\n",
    "        sum += cond\n",
    "        if r < sum:\n",
    "            return cont\n",
    "    return None\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def get_random_tweet(n: int, n_gram_model: NGramModel):\n",
    "    \"\"\"Generates a random tweet using the given data set.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    l = [\"<s>\"]\n",
    "    for _ in range(n): \n",
    "        suggestion = get_suggestion(l[max(0, len(l) - n_gram_model.n + 1):len(l)], n_gram_model)\n",
    "        if suggestion is not None:\n",
    "            l.append(suggestion)\n",
    "        else:\n",
    "            break\n",
    "    return \" \".join(l[i] for i in range(1, len(l) - 1 if l[-1] == \"</s>\" else len(l)))\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "37e5cc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was buildilng https://t.co/KBkladnmPQ car https://t.co/XLoCxOFvMA woo Walter Inspections https://t.co/bkmWFZ9JI9 #SaveCulzean https://t.co/YPB8nqX2d6 Opinion Kong Katrina @Netanyahu https://t.co/VU5wh2zXBU technology Income Rancho GRANITE Glimpses mysterious Wacky challenge @hookjan @CAKairport https://t.co/ZnPgnu8vCS #classact http://t.co/ZnT7ayNBiC https://t.co/MwWfmZjQIN http://t.co/BYFRxtzJ Behar http://t.co/RKVJ8h3V1v\"\" parties JebBush overwhelming Taxing minuses GRAHAM path http://t.co/fBxho8MWgh Fracking https://t.co/y1j2Wf6J4p http://t.co/LhK8EfIA https://t.co/FsrUGByuuD @DangeRussWilson #HandsOffMyGun Factory Mohammed forever Problems @freeillinois TrumpCare Ivana http://t.co/PpCgzJwr http://t.co/r3zVN62W Petersburg @RobertSuppa Garrett @mike_pence @frank_puggi Pressed Historian divorced wee @mtshastacola precautions https://t.co/HfuJeRZbod https://t.co/hJSsx86Azp Steele Castle Although #SemperFidelis CONTINUES memorabilia https://t.co/u5AI1pupVV https://t.co/YsZUgtNoZW https://t.co/bYdaOHmPVJ agendas https://t.co/XTSFEoxyAM Following @parrguy @Graeme_McDowell Testing http://t.co/sWFmZzsaaC counted fares @Cynlanjoh http://t.co/yuMqsrT6 Wade chopping WINTERS burying wings Slush Labour SANCTUARY https://t.co/3YQYZR8OzS Prosecutors https://t.co/30sGVdMDLu betterment https://t.co/cYpx4eC9W airbase ONCE reserve Tower pathway standards Agents https://t.co/3jbDDN8YmJ PRESIDENT http://bit.ly/rsBqmE Makeover https://t.co/z5CRqHO8vg taught @paulwesley #NASDAQ SuperTuesday Built spewed http://t.co/IkmqEQz4ef pulls smile growth http://t.co/EplLsBWgBE Ballots CHAOS https://t.co/m5nPdUHt4u http://t.co/pMzy2rB3 pinch http://t.co/ZKJexYr9 Coyotes http://t.co/sg8CCSJMFB paypal phenomenon sexting simply am Sanctimonious Bonuses https://t.co/CYG11DnxH7 Karol http://t.co/QHAkXuH8CC GOPs contradict https://t.co/lFegwHMLGr https://t.co/0N4AeoRWK9 OWS https://t.co/LZ9qWRYzdj http://t.co/YGeFcDz6Vo\"\" Meyers @FoxandFriends http://t.co/9pNc33EVvu\"\" @NewsCorpse https://t.co/g07VZmNmAW restriction http://t.co/kI1xij3v6w\"\" observance Fund @PeteRose_14 Selective chutzpah #CadillacChampionship spelling FOX @cadillacchamp https://t.co/Oax06JVzv1 Wiedefeld @SemiNoland http://t.co/sWFmZzb78C http://t.co/gLIQUPbLnV strength speaks influenced @HaloOneForTrump https://t.co/iSzJDM7CZw Doonbeg https://t.co/yoWCQLM8Ad Traveler Rose middle @erictrump @Wicz_2003 forties Creates omg Huawei postpone Membershiphttps://t.co/GwWRxT3BVp Typical @PatrickJFSmith couture @ChrisPedersen80 http://t.co/RMI02tjB https://t.co/T42kUChFsi Nancy https://t.co/XgR4kiOANB forgets Prime Kabul https://t.co/hab5WLhtrI @brasicingbras par crispy CPAC @MyStudentApt westchester https://t.co/zfvJpyjVoH\"\" Gillibrand controlling Cleanest EXECS https://t.co/sgblnB0EgL Blowout http://t.co/utITLy38bm Unbeknownst https://t.co/ta8ii8yetP mother smoking https://t.co/s0T3cTQc40 @IamToneAntone SPINNING http://t.co/HUTV6CDphY\"\" introducing Cattlemen @nmbr8 https://t.co/lQtpC2rD6I predicts overcapacity Slots @laraleatrump acumen https://t.co/xxvIrqObDs http://t.co/u9gb8nY9 Fabrication woman Sean http://t.co/dhLnMUxKW0 ranking http://t.co/eNgkidCD embargo TRIUMPH Stranger combed https://t.co/2FtrIcqO1B http://t.co/A4pgF5Xh https://t.co/WHvhZpyqAG Frieda https://t.co/DutxclyZw9 http://t.co/8YMD9fQH imagen https://t.co/p8ym8S2d5o counties https://t.co/mK3SB7t3EV @GQMagazine Council #obama pairing Car Lubitz http://t.co/6xUs8cMy Registration slammed Portman survivors @ladygaga grieves hope naming organization https://t.co/mNB4KMEj9u Smarts @stpatrickscath influential stay manuscript https://t.co/XVwzt3Me5d stampshttp://t.co/OD3nBmsK Frack https://t.co/zVmhYsd4ir https://t.co/qCDljfF3wN https://t.co/Y3LLPPg3eG pitched http://t.co/LIBmCVDs https://t.co/bbroAGTdMw Mick http://bit.ly/ckmKKU Hale Magnificent Jay http://t.co/fwIZR6XhYP\"\" @MichaelKaye_3 Poetry @Gonzobeachboy Lipton apart lied http://bit.ly/11FHpR @msmaddiexo http://t.co/oUe7JRnf private HARVESTING https://t.co/Tj85IsBPG8\"\" guilt https://t.co/xGevgI2wTO proud Economic news listeners ace ststement suicidal #bestshowonTV http://t.co/2M1jSV0W Favor Overrated @MTA Horowitz https://t.co/RlJvPxuVvh friendships #Wisconsin brutality http://t.co/6Zbad1Vr egregious https://t.co/2ahAvm4n9s NBC inactivity #USAatUNGA https://t.co/06OZcBE08b mistaken https://t.co/bTPX9E0wKu Horrible @ABCNetwork 6G @RogerClemens gap #LEGENDS @CoachLouHoltz88 aware inflow https://t.co/izb2tTrINB flagrantly labeled https://t.co/R751UfHQ0A ink http://t.co/UpURDegT8H brothers http://t.co/L2slCWA5cO http://t.co/yUn5d14t0Q RINOS http://t.co/K3LkNvub2o https://t.co/h78ESEgEYg cherished Tourists http://t.co/zufZfBxOw2 Henry Deutsche http://t.co/Yo6s4Az5Fq http://t.co/syk1ZiGn8y Fading touching FoxNewsInsider http://t.co/fokcASBVuN http://t.co/MtwYtrNz https://t.co/Z5VwluvJQx Gaga performing Redstone https://t.co/pN1azBRVT5 Rating Person after @sfchronicle @Yankees @CaroleCJF Londonistan @rilwanemeje Horace manufacturers Markets https://t.co/HHTwwbuKa2 warrants segment http://t.co/lDq59Zyos1\"\" dropping amputee ted whitestone letterman http://t.co/K7vvbzEF luckier https://t.co/7ImVH69fNb https://t.co/4CFzQXb5aS Properly https://t.co/73kpVWrugh SEPTEMBER regard publicize http://t.co/Yhs8s8UJ sponsor Cowboy McSally #makeamericagreatagain Sharon overthrown fried @SHANEDIESEL777 toxic https://t.co/tbl94sCM01 Timing society 23M سرکوب explores Between duplicity JCOPE del operative Craft STIRRING @WhiteHouse anyway @vikinggroup1 Ian حقوق https://t.co/iZcL0U92pZ https://t.co/m4VWxYvONx Parts Effort @tinaclean Fitting https://t.co/yKxUBasreY documented Witness https://t.co/d7L1YW5iVY activated @gggboxing Crack @EricCantor Tank booth https://t.co/weQBW7xKic #G7 @insighter007 https://t.co/wbSLJ4snxX suck predict request #Marine highlights https://t.co/Re655JmhqJ\"\" Ari past https://t.co/ib2yB3Akkt simulcast Navid ninth https://t.co/V84qfN4oz1 unleashes @mariamenounos @PhilMickels0n_ Soars classy https://t.co/BffAhzSDdi Peters Seaman ad NEGOTIATION https://t.co/Xi7yQ45jvy LEGAL Arrive Redo @kneehighspy Kazianis Ken painlessly @BrikMillerEDG wit https://t.co/n026nE4XIp Gretchen @lansing https://t.co/3i6tgfqrRl https://t.co/n7qKI3BbD2 @Amazon https://t.co/UhTjBuWY2h http://t.co/bi2VmLJE censorship Dominates https://t.co/57tngL1W2i http://t.co/5yE8vD0HRq @goonerdad52 36th Jolie children easing panel https://t.co/MDzpY89TRE @rginn_1 uk https://t.co/cxhgYaxiek output waivers @dgibson120 @RoySchuhmacher recordings lakeland nails react buyer https://t.co/CBxrWeRZhP http://t.co/0842B3yZ Night Altering REDEMPTION https://t.co/6NI6AqL0xt Popularity blanketing online leftist https://t.co/FT2ERbVPf6 https://t.co/6snvQ0DzXN VOTERS Donations https://t.co/0OCL6IFp5M Form #TeamTrumpPA thoroughly Controversial Towers counted http://t.co/4dMRqAid shout Sue Rank http://bit.ly/fMNVbx @SPANISHFLYAR09 Sophie https://t.co/O1QiZSw4cU @OraTV https://t.co/iqtuwzbaIV MIND http://t.co/cdYT5btamI\"\" humiliatingly includes CHAOS glistening @1fos1 Vetting http://bit.ly/kJWdvX restore robs stiff vassal http://t.co/Jm3YSf7h Papadopoulos folks http://t.co/RYjv5gIooP\"\" https://t.co/phRMudujxJ Businesswoman schooler Liquified Horrible https://t.co/XuOMzYSnwv Except Verification #Establishment https://t.co/2ToWwthEeF rehiring @penguin_rob remembrance #lovetrump https://t.co/WfnIqs6BsE embarrassment https://t.co/D0MeBJXBwN https://t.co/4m6dabtxCV Handle https://t.co/5nVH5AT2Fw pled Rig Wintour Treasury http://t.co/Stq7jiomjr https://t.co/2p4WngYWJ4 Carli @IAMAASHKA Tonys https://t.co/vpCE5MadUz https://t.co/RNl7cfzkmN Papers german nationals #MedalOfHonorDay https://t.co/dvZq0UPjHI https://t.co/cKVa2HlJQb https://t.co/okkpcFyO3n #Godspeed enhanced http://t.co/seLDvy28 https://t.co/XcdyhWQI3d @McConnellPress complained #Teachers4Trump https://t.co/t2ocHFI6H3\"\" Equals Joy chairs dispatched mentoring https://t.co/DL3oan4Fm7 http://t.co/QhlACcNK attend monument REALITY https://t.co/Hqn9wEIXo9 https://t.co/cyRCfwxJg3 https://t.co/mNkDYgu5sr @KingspeedSimms https://t.co/VqpNDMua5X Doctors @carloguderian Linda POTENTIAL @toddinwichita endemic hella @tbott22 https://t.co/Uc9Txu7O8g @MikeMcLeod14 bring https://t.co/lanqvbZfJj LGA https://t.co/dO3Nr8nuJi Homeland http://t.co/f7oPZEBUVs Building @LanceGooden intersection https://t.co/JKkiPxPL0X 418 http://t.co/wLn2pV1q misplaced harvesting scent disgrace https://t.co/1tZfqVETrX decoupling redesignates layout indecision spur @OfficialBQGirls spiritual #TrumpPOTUS2016 PRETENDING http://t.co/TgYWt4my https://t.co/GFLxcNJOkk cameo HilaryClinton curve turbulent @Mr_Oghene Fascinating depress @TrickettTweeter @townhallcom @bvogel56 https://t.co/zeRFGhMQqd http://bit.ly/jxjHgU @00RSTW00 @WSHEMP Records Wrong WALKER https://t.co/edjugpzH0i Runoff bent SMH @LinkedInPulse extend Cattlemen BALL shoker hay https://t.co/H9NlPQj5yb https://t.co/wTCd108yrV wastes spice @OceanDriveMag http://t.co/8ozY6pYo penthouse profusely http://t.co/JP9isP6SsF http://t.co/jPoOB7OsTG\"\" http://nyti.ms/e9u79i https://t.co/0rnhb4hsjk commish @Peggynoonannyc WarrenBuffett http://t.co/6rzfGjMM https://t.co/ZXDKA5TYBo\"\" socialists http://t.co/jWB6i1qtHX conceived http://t.co/Fmd9eFt606 #VAMissionAct Coalition http://t.co/I5CybmR0MF safe http://t.co/8KjL74PaNe finite https://t.co/7mIkwAHTuV meetings https://t.co/IFcjTwd5ey\"\" Delivered Idiot Low Brexit Finish https://t.co/kQbKViF7Il http://t.co/fPpFEby5mV #KYGov unattractive Brooks BLAME #HurricaneNate Ft sparks https://t.co/1GVq74iW8a inch combat http://t.co/DJ7OqXwx Screening @MenOfHistory https://t.co/xJ9QYGMJXa Hard @JedediahBila stupidity http://t.co/VyM7u9dw warmest memo https://t.co/DoahM18IuK http://bit.ly/ff8tRT @Eamyoncanoe http://t.co/JathcK7j Logo Synagogue https://t.co/ii8ZUttL9D @GlobalGolfPost viewpoints @EdRollins fire Justifying @toptv005 patrolling https://t.co/nSmc2olraF #learn Welker feckless https://t.co/uV345JyDdF\"\" @SteveMarz1 QUESTION mobster https://t.co/LU3hIeek0c https://t.co/FxyBL6fO1h @realArthurSpina medal denied bottle #snowden http://t.co/mP76RKHT Phase https://t.co/3YWJOo6MnZ @AndersonCooper aim Protection Kuhner Chester wipe honored https://t.co/5vlnzRg6GN Menard Paulson Gymnasts @NoyonitaLodh http://t.co/IPsMY8Jsx1 hitter NCAA TT @FLGovScott Sorta https://t.co/msBoZ1TbNX vitally Sophocles Then wimpy defrauded Schneidean orchestrating https://t.co/UM7HCfyBhp @RepCummings BULL https://t.co/uUNCL1hPAk @iklemieux retakes specialists @kmcs1957 Attkisson http://t.co/bVF89yZOFJ @jonareeves6127 Plain https://t.co/gGC3uuldxh @designergirla http://t.co/m8aFG5sb INNOVATORS breed envy ears https://t.co/aR8iwO6Gvl spilled share Processors Beatles Indonesian designation resign Myanmar y billiions UNEMPLOYMENT emanating https://t.co/du665IcD5H road https://t.co/q45tTapqMI http://t.co/hWRVkgUDC1 reclaiming trillion awareness https://t.co/6a7Ef12giZ @TheRedDotGuy inoculations Salon @HammerleAmanda https://t.co/sO5h9LmIMg routes @Denver4VA @JoelKrautter maxing Representative Waldorf Gates jumped selfish SUFFER Terrence @TimeToGetTough #badratings https://t.co/tU0iW3Gi9v knock @Sandikay60 boast #RealChange https://t.co/Nx1QykXAE8 @loverofthecross blonde arbitrate @OCChoppers needing Lorenzo INFLUENCE https://t.co/Mk0WSyjdOe Threatening lobster ISLAM Bureau Yaemwannang posing #C21 associated lost digs https://t.co/q43kHf7MoE feeding https://t.co/M0iiESm2fJ Clemson http://t.co/WRqy89Ef1t\"\" @bubbawatson Hans https://t.co/GQeQpJOgWz @SpeakingTruth11 Proof https://t.co/D5fG5cY25U https://t.co/qGKW2xGjP0 Envy Davos https://t.co/XNMJQ5JDSU VERMONT observance @KSherrill_4 Plant @RepDLesko newsroom @TBrown2334 #MI08 overcome consistently blatant Kabul enhancements peak crossroads breadth @SonnyGirard https://t.co/HEXBZeejBc Meadia https://t.co/ZDlBDehhvN local https://t.co/ZL4Q01Q49s https://t.co/RPX0fqWmB1 https://t.co/SgWL1HZmkI shift http://t.co/YMP2DPOUAK https://t.co/28q3QgfIbM Stoltenberg exporter http://t.co/ubaVEGYn pillaging PRESSURED Barletta Defense #trumpnationaldoral http://t.co/09bvhYUR @StuartyPhilpott miracles oars #Vine https://t.co/vYLULe0o2K @gazettedotcom secrecy QUO compare http://t.co/Bco0a2AD @JulesPQ https://t.co/HqOUFgmbQS loans http://t.co/KPzXEn9E Dawsey Simi http://t.co/UOC8xu11z3 LEAGUE WHICH JPMorgan https://t.co/wyjBAgoF7J #CARESAct https://t.co/8DgCjsEM7k https://t.co/RUAfkv1cOs visionary http://t.co/aYUkRiKy quadruple shelf Enron https://t.co/SmjNuHi7XB https://t.co/D5fG5cY25U @mala13slp https://t.co/5jxdojPZmN gang pt Advisory congregants https://t.co/mpusBndpcH @NYGiants Lucent Restless codes @wbtwnews13 shook atrium clandestine Scotsman @govkristinoem bball PPVs Life Delighted framed Lauderdale grandeur http://t.co/23mmupZcLw\"\" https://t.co/Rs5brj31bA credence http://t.co/QhlACcNK caps http://t.co/Ny6RxVYiP0 https://t.co/u25yI5T7E8 https://t.co/SYuRpzosb5 unrevealed https://t.co/ffydSSVnGL HAUNT @Forbes #noratings prove @nhiop https://t.co/suoRN02zMq Buckminster deferred SECOND @kristinkgl Ttump https://t.co/wbSLJ4snxX Urging https://t.co/ZU5MovNKt8 https://t.co/k92cslgKFa Knick some1 https://t.co/Lgjt53B7QX #MTSEN http://t.co/gLPRy9lS http://t.co/J1FEV8eHg1\"\" joined https://t.co/jQTQYBFpdb Recovering Environmentalists evening https://t.co/BDXdpelK7F guys REFORMS #NABTU2017 @POTUS juggle https://t.co/x4RbbKXHCu hub 4000 #JimmyFallon https://t.co/rO3EkzzkVA GOVT visibly crown https://t.co/T4i0UYqLqd Battlefield AMEN going Bullard legislating https://t.co/hIw1AQdRpY #Millennials Opposition http://t.co/WntDZ0BI1U\"\" #MTSEN @316Place Funeral SCAM دنبال clubhead https://t.co/eoDccVFzJS Consult velocity https://t.co/aCaMtOUAl0Remarks: https://t.co/rLwXxBxFKx @alecmillionaire @LKDUSA http://t.co/Q3ONewMKKG remembers Kane https://t.co/8fLOejOpxH https://t.co/EXGrLh9dQt keeps Waukesha @kevconnorsespn @terrellowens def @WSJVideo @ThejustinMiami gotten https://t.co/vhmv7Qoutk exorbitant http://t.co/14lpNtixNX\"\" 7K http://t.co/vPG0IN5qCi\"\" below Decent come Pontifical observe https://t.co/Zm6Lqzgppq 2011 remembered @gma Dorothy 1988 https://t.co/jowS1B9qqf HAPPENED https://t.co/le48VOltE0 Brigade announcer efforts @NancyMace https://t.co/yl5ly5nwdv personnel Commonly university USMCA #FREEOURMARINE @milkncookies70 http://t.co/6CApIQUPZc\"\" https://t.co/5GaxLp2piq fade http://t.co/wbFc2B3QQn planned https://t.co/XE7ofTy7Sf @craigdevlin tons https://t.co/sMoLTsiSAk\"\" Kerr EARNED FRONT site http://t.co/7SRYZNQ1 https://t.co/pf2feOSYX7 @not_that_actor DEEP @DavidBlanch boarded https://t.co/9fRvjIgqKE @gameexpress1 https://t.co/42ImacgCN0 pr http://t.co/Xjimd3KU FLORIDIANS advisement @JerrySeinfeld https://t.co/Y8HRT6wnWZ https://t.co/jjnVrVgQWY https://t.co/S0S6xqrjSC vigilance sprung http://t.co/4tCiuu97K2 https://t.co/xoxgi1vVP2 https://t.co/ek4VGj0p0s offers PREEXISTING OPPOSITE instinct Genius Danielle TRIBUTE https://t.co/zGOx74Ebhw https://t.co/XoDkW5X3Wy Nor https://t.co/OfmL1fPSjZ prosecution willbe @OfficialBQGirls #SilentMajority HORRIBLE @PatrickBuchanan based Macon perks omarosa EARLY Brotherhood http://t.co/lXPVsOpadu @TradeArabia Illustrated @Saran_arsh #Wrestlemania4 http://t.co/hu07KWdBjF @jeffldye commemorating Emily @ProducerGedalia accusation http://t.co/WIH8gDAyuH @Kevin_Johnson68 entails https://t.co/KSAgyPPmGc http://t.co/XCUB4udps1 @vdare https://t.co/xEj6sZpb12 Hey Swampman @UberBurgers http://t.co/LnDC52GfKD Concerns Crosse HEADS https://t.co/02Pyyy3kHH wack portrayal http://t.co/EBvEeowjKL\"\" missile Additionally #MarALago FLAILING electronics penthouse Rickie TERMINATE @SASCMajority Caddell https://t.co/10fmssLyDE\"\" https://t.co/xhiknXko70 http://t.co/VmcJZAO065 https://t.co/HYfBmtYMqF dotting Unconstitutional rewrite مردم trustworthy @AlCardenasACU @destiny fires @pgahistorybug @LateNightSeth https://t.co/FUtGBoTJLo arrived spike @crazycatkid needing ads http://t.co/j095jFo098 shaping unpardonable colluding Verdes https://t.co/ZmZgqwlimn Broadband https://t.co/ZGiqdYbats thrive Formula @tdragonfly 30min FREEDOM founders ATROCIOUS http://t.co/5aeyPlLFzp Grapes #weneedchange http://t.co/HEP1kOlty2 meager Renewed Hussein resting https://t.co/AQQzmt10x7 Tone @rickwtyler spoof Iger referendum ensures https://t.co/onl1HmM2Gz http://t.co/iqDO4rUNhN Strategist Garland booed Buren funny overturning https://t.co/Vu2b2hhwHu amazes suburb Northam River rocks http://t.co/t9vhQRDk ruining incompetent intensifies http://t.co/tGJEeapJga\"\" handle LETS https://t.co/IJu93xjiQS admirably @BestNewProduct AWESOME #NationalDoctorsDay @BillRancic roving @TheTyler_S Buffett https://t.co/Ui8bubj7Yr #Sandy @foxnation @JoyceGoodman64 @CompaqSstring3 hits refitted Tix magazines @LUSHPILLAI #VoteTrumpMS fear Holtz https://t.co/ssFXVGWTIP http://t.co/UrrYw3uF https://t.co/28G3RVbFsnReno: counter Cathy lavish https://t.co/LsKLZNeZL9 fucked https://t.co/BHBGMYMpc2 flunkies https://t.co/lIlZBxKjuG NationalGuard https://t.co/NmdLNsfDU2 LISTEN BOOM #PlayTheTrumpCard Monster fill Wins FIGHTS https://t.co/RSZF12Kyhn @bonniebell Dany @AndrewBreitbart Powel #politician talented #G20Summit @cmtoms101 tragically @WrestlingInc practices earn https://t.co/FXqSWusSTV @underworldfilms effects @KennethHazlett appearance pizza @PrinceRoyce http://t.co/8nz9uLd8 Ports https://t.co/hwDICbpOT7 https://t.co/S72PSSLwtk https://t.co/Lwc2ns2mQt @seanparts http://t.co/sgxLK2Ca4V https://t.co/kyPZwHsBDQ @danpgabriel https://t.co/aR8iwO6Gvl PAYS Evers showtrial permission @DAM615 parking Iran disparaging https://t.co/XrJSUsm9Wq treasonous https://t.co/B6NgsZuJdy HC rapper http://t.co/2pka1VmdBz http://t.co/Cn5g4xyage\"\" http://t.co/XxOxEhlCTB STRONGEST letdown approving https://t.co/BnMB5mvHAM @Timc1021 http https://t.co/cQ3B1bGD4L @KingJames Tops https://t.co/LfXqfVEvx1 https://t.co/74z0n2icuA https://t.co/6VLQYAlcto anonymous relies https://t.co/RldaoFw0Uc @RickAllen @ukcarioca Laredo #WorldChampion Kinston #irishgirl undertake sellout strictly PATHOLOGICAL felon #LightweightSenatorMarcoRubio http://t.co/rhm2EKdwSf\"\" PASSOVER Sunset rebuilding http://t.co/Dz3gWGUsZb https://t.co/sPnloffJMT http://t.co/v6ftE4InKb Marcus @milkncookies70 Sutherland Grocers https://t.co/bOMJRK8FyK @RickyTheBitch https://t.co/qIef5VhjDr @cnsnews Golden http://t.co/cwnjS0VBPz TEST 228 @MichaelArrante #MaraLago https://t.co/L3tOUDiT0G Person @RickCanton 2001 @MikeDGarrison usher 15k Bombings https://t.co/Fn8C7IoZaF Inexplicably shld https://t.co/F2t0SMiwLr Intensive MT #BigLeagueTruth hubby #Chicago vest Shannon Militia #NikWalenda posts Guam viability PREVENTS phones Hôtel divisive @aa_newey innovate http://t.co/iw7so3Y3 contributing Faulkner @LanaH11 http://t.co/RRgM3Xxr http://t.co/BViQaP1MLY Deals @LoriMoreno #Hypocrisy @JJcompitGolf Dumler RESORT marketed avoid http://t.co/h1cfQkEmRQ parking hero Nikki electrified PayTribute Showing But Kellie #C2GTHR flawlessly Export #3 bankrupted analyze https://t.co/IwLEO9ff9X Pence @pareene Barriers http://t.co/ZPV0q43j #ABC2020 https://t.co/fSKOf0Jz9K Safety jonas shopped Birthdays RealClearPolitics embarasssmnet visionary norm Waterloo https://t.co/RwaLpCRPh5 prepackaged BREXIT framework https://t.co/bTPuerxLOr @AccessHollywood shot @morg25016893 #SNL https://t.co/6S6mP6yH3A economic https://t.co/JxzM7kThko drumbeat @ArthurDeMeyer https://t.co/yjWiLBGUpm http://t.co/YW5q4n3X Contempt Endless spoiled Superman SPIES https://t.co/HVrucgzWfs http://t.co/fsApohRoYP Frances https://t.co/dJlZvlq6Tj Wikipedia http://t.co/wN3COpsj fully http://t.co/UNIaZZtsnJ https://t.co/RHryqijTlu https://t.co/tfWXWRuy8q COX Offers transcript https://t.co/CP7N9ASHKJ Victoy گوید https://t.co/3zM6LVqYn7 any wtf Beltran https://t.co/qCDljfF3wN 252 belittle betrays https://t.co/kVtop3WsLp supplies Substantial R Biased Taken settler Ned https://t.co/tFxHLSqcBE https://t.co/w0zb668avg\"\" chosen https://t.co/45q70Ps7oK listen cheered http://t.co/e92WHIBCBj pour https://t.co/FyQdgKvsRO #Media https://t.co/mMSxj4Su5z RINOs Kidney Rephrase Orthodox 72nd tied @icsc Clare https://t.co/jAOZ0CPYO4 https://t.co/Feb6dhctQo @Newsmax__Media Chapter http://t.co/GWGw43UH https://t.co/xKVZMVnOQI Uranium Protests https://t.co/1ziqFq9S6O @WattersWorld #AZ Securing @HerschelWalker ruler wedding https://t.co/m2yw7gTU5q active worthy obstacles YR Cher https://t.co/L1HDeXWazc shooter Plouffe ISLAMIC @MONIKAKOVACS TERRORISM Institutions @kirstiealley quality Launches @TheFive Europe https://t.co/JXkiePOLMb viability https://t.co/iNolBfFFRF\"\" buzzer http://t.co/RVF4ZHUeCk http://t.co/h7pVSrSxhU shoplifting Medalist DIRT @11AliveNews @trace_barden https://t.co/fFN9pisyQ4 https://t.co/74sqFSP4o3 @SenDanSullivan Powers http://t.co/Q6oQdAdiis @TheRealRoseanne accordance Stable dismantle utero militants otherwise @lawrence mall @PGA Zone Mexican @TheRightScoop @BuzzFeed https://t.co/MsGVgODwVU https://t.co/zxy6zRLGu1 https://t.co/AWC0HLAgJD leaks @ManagersDiary aircraft NV https://t.co/GnKoVz9GTO @Real_Carl_Icahn Chill punch https://t.co/LCQcdlRkhz beloved Peaceful shots @sprinkler22 DEFECTIVE Defunding यह https://t.co/Snhv08ulcO https://t.co/0TnmLn55Lm https://t.co/Zauqz4jfWv Natalie https://t.co/7mIkwAHTuV serviceman Avenue https://t.co/8kvQ1PzPAf #DNC threw keynote https://t.co/qTMiYoR9wu #NCGOPCon @americanowradio leaks @3nVMusic prior @JesseStroup https://t.co/1J4vZiy98y http://t.co/LldABpiLaQ\"\" Alerts tests @Sherry09 Edward https://t.co/pUVreuusxz @dish http://t.co/HRj7pAcvft bullies @pennjillette @kleckhardt bowing crushed http://t.co/ws4PiIkK @Poetry4Bitcoin https://t.co/DYxkh3gj0R Wooden undermines https://t.co/ZnPgnu8vCS http://t.co/FrP19xiK cans Hatch hopping ObamaBiden @kpdelbridge lambaste @JHKING17 @Yolie4MS chokes ROLLING karma 302 smears @rupertmurdoch devotion Facts birds PREMIUM Stonewall principle LOUISIANA https://t.co/oFvr0DJMEf constant https://t.co/pxLUeoDnhF http://t.co/ckRwPXLB https://t.co/ZnPgnu8vCS http://t.co/XXQavT8KwO deserter exhausted adversely https://t.co/6G7hVhrtiY @nytimesbooks @jimmymcgreevy EPA us http://t.co/6a1rJoUz https://t.co/efAolmZvuW brokering https://t.co/A6FmrLBohO http://t.co/YFumzn95 http://t.co/zr1my5Vprh\"\" @teresa_giudice https://t.co/CP9azm8U54 stripe https://t.co/0wz3UZgIuj South https://t.co/TcNTiAuvrK\"\" https://t.co/h51DpgM9JK Barracks organ pharmacist http://t.co/LI75orkoqT #HillaryForPrison2016 Pressure Inspector recorded https://t.co/5ppZhQhZu0 Meetings @TheLeeGreenwood capture @Algemeiner @myTDOT Bay DOE Tell https://t.co/XF8o3jMDle https://t.co/e3KQfBR2K8 http://t.co/dcTOq3QZ http://t.co/jilJv0DF https://t.co/bomRqsaYfm @TomBossert45 Int @telegraphnews Surpluses wildlife Have trending http://t.co/CgTTujEi6K https://t.co/yQmh3iSPBY\"\" http://t.co/16WTPCHy https://t.co/uLuDOHEIB2 @DelawareDOT https://t.co/JIkrIczC8o https://t.co/YPMtXgKzrD\"\" commend http://t.co/s2jhbivz violates terminatrd https://t.co/2NnItfwfBl affidavits @statereform @PaulSRiddell https://t.co/QeUbwdsWfr @Fleur498 https://t.co/gN7BYfLD9K http://t.co/1YMvzIOnfI https://t.co/dR6EzS3Q8L congratulated DESTRUCTION PPV boardrooms #TrumpPOTUS2016 prepaid https://t.co/RRcFE1AHjR https://t.co/Aq4Qus3u4r Challenge @lynn5101953 http://t.co/W80SNXR75A\"\" retrospect @TexasBlingMom https://t.co/xhqhUVXrsx\"\" statesman strikes findings polished https://t.co/YwZdQdzKcz outlay Emin @PlaysTrumpCard @nytimes greeted electorate https://t.co/hQPC4CrhDi commercial @L3nny85 espionage eat 17B stature https://t.co/ODAEpPur3W perfectionist underway weed ineptness contesting @bobbybnews misrepresent @Lood800 https://t.co/Acg0hMvrpr carried https://t.co/pxe9Z4efyZ quiet Actress VETS pyramids https://t.co/qzxn6Svlpc Lowell weaken https://t.co/RqdYnfIExf Vienna hindrance OILED http://t.co/X79a8dpyQA\"\" روشن @miamarrazza http://t.co/778bc2kJxe no https://t.co/QIpH7RDfAV Chera http://t.co/7Tgnnje2eR @NCDOT http://t.co/jBPL1wWf1i shaker https://t.co/L77SXS2mE8 EpiPens @GolfChannel Franklin Breakfast orchestrating 5 Ransom http://t.co/UV1XwDd7wF\"\" rebuffed http://t.co/dlErLZAE Provision @EricTrumpFDN https://t.co/zPTtDbrP0o erase @IranGovt Deere 4months http://t.co/Kp5ntVlAoU\"\" خواهد https://t.co/C0h8cW4FuH https://t.co/gfRMOu2zVM @JAW44444 McDaniel Mauricio Lick http://t.co/KzVvAk7euD\"\" #LieOfTheYear FOP Paolo https://t.co/zuI0QYYCaQ homework representation Pierce https://t.co/CXK0LFpGMD https://t.co/3KpgUuRaXU Attends hanging substantialy nestled debt become Nears SOMALIA http://deck.ly/~x0TDx https://t.co/52E3LU3W77 lunatics @BrandIdeator @twendencyUSA groveling place Patio https://t.co/fnzZATqHXz http://t.co/VMJy9XjJ https://t.co/XL9LLNKh8i http://t.co/J0QeWXy3 @BrosHoban @CadillacChamp https://t.co/Gm9KE8cHpS @woodyjohnson4 beside Lottery Hoover Inaugural @jchorvath11 staggering Mob @brucedhendrix @RAW1183 lifts wondering grades http://t.co/iLOtZA6z Madame Swecker horrible unbalanced nbc includeTrump @babyguts666 Emily Sacrifice humility https://t.co/OzYzLQ2FQp inductee @CelebApprentice http://t.co/hR6kBhUwBS substandard @DHSgov http://t.co/b9E5eC9pam https://t.co/UEFJRKsVh8 PRE sucks seasons knocked latinos https://t.co/lacUQC6IHh http://t.co/D2KyOMsQ Reputation heading Destroy dump https://t.co/BjnyTnnHUt Becki http://t.co/pVHA229OA6 believes @andydean2014 dire http://t.co/wqzRKvpaa9 saving activation http://t.co/uguSSXyTO2 Benjamin Knowles https://t.co/i8IMLhH53Q different nine cattle Maithripala @minlarrycornel https://t.co/t6R84x4PbP pc http://t.co/MS1vlLbNCm\"\" income http://t.co/IwziHG38WV @GOPconvention audit Hater @LindaSuhler stretched https://t.co/FH7NcIPqDp plummet crank unit http://t.co/iy34KnpowZ Swecker @Deelaney31 wont expansive principals https://t.co/6vHEaB37VH Realize @GeorgeTakei https://t.co/vNW3I3pPNK @DonaleeCurtis Pastors @bittyandbeaus Sin Joined https://t.co/k98LQLPwsK http://t.co/maobMmCu4L Biased seizures dominate https://t.co/TWAb8u9KIS https://t.co/np7KYHglSv @AmbassadorRice https://t.co/tyqbvvmBn4 Telethon http://t.co/ptk8Of5W Brandon handshake\n"
     ]
    }
   ],
   "source": [
    "n_gram_models = build_n_gram_models(5, data_train)\n",
    "random_tweet_trump = get_random_tweet(2000, n_gram_models[TRUMP])\n",
    "print(random_tweet_trump)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648216bb-a49e-45ff-bb8c-9094c33acc07",
   "metadata": {},
   "source": [
    "### Classify the Tweets\n",
    "\n",
    "3.1 Use the log-ratio method to classify the Tweets for Trump vs. Biden. Trump should be easy to spot; but what about Obama vs. Biden?\n",
    "\n",
    "3.2 Analyze: At what context length (n) does the system perform best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "99dd4ca5-8094-40b0-aa1b-a51268659397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_with_zero(x: float):\n",
    "    return math.log(x) if x > 0 else -math.inf\n",
    "\n",
    "def calculate_single_token_log_ratio(n_gram: tuple[str,...], n_gram_model1: NGramModel, n_gram_model2: NGramModel) -> tuple[float, float]:\n",
    "    \"\"\"Calculates the log ration of a token for two different n-grams\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    return log_with_zero(n_gram_model1.conditional(n_gram)), log_with_zero(n_gram_model2.conditional(n_gram))\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def classify(n: int, tokens: list[str], n_gram_model1: NGramModel, n_gram_model2: NGramModel) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    Checks which of the two given datasets is more likely for the given Tweet.\n",
    "    If true is returned, the first one is more likely, otherwise the second.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    log_prob1 = 0\n",
    "    log_prob2 = 0\n",
    "    for i in range(2, len(tokens) + 1):\n",
    "        n_gram = tuple(tokens[max(0, i - n) : i])\n",
    "        new_log_prob1, new_log_prob2 = calculate_single_token_log_ratio(n_gram, n_gram_model1, n_gram_model2)\n",
    "        log_prob1 += new_log_prob1\n",
    "        log_prob2 += new_log_prob2\n",
    "    return log_prob1 > log_prob2 if log_prob1 != log_prob2 else None\n",
    "    \n",
    "    ### END YOUR CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "97d1e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "        n: int,\n",
    "        author1: str,\n",
    "        train_data1: list[list[str]],\n",
    "        test_data1: list[list[str]],\n",
    "        author2: str,\n",
    "        train_data2: list[list[str]],\n",
    "        test_data2: list[list[str]],\n",
    "        classify_fn: Callable[[int, list[str], NGramModel, NGramModel], Optional[bool]]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Trains the n-gram models on the train data and validates on the test data.\n",
    "    Uses the implemented classification function to predict the Tweeter.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    for i in range(2, n + 1):\n",
    "        model1 = NGramModel(i, train_data1)\n",
    "        model2 = NGramModel(i, train_data2)\n",
    "        ground_truth = [author1] * len(test_data1) + [author2] * len(test_data2)\n",
    "        preds = [\n",
    "            \"indecisive\" if x is None else author1 if x else author2\n",
    "            for x in (classify_fn(i, t, model1, model2) for data in (test_data1, test_data2) for t in data)\n",
    "        ]\n",
    "        conf_mat = confusion_matrix(ground_truth, preds, labels=(author1, author2, \"indecisive\"))\n",
    "        print(f\"results for authors {author1} and {author2}, n = {i}\")\n",
    "        print(\"confusion matrix:\")\n",
    "        print(conf_mat)\n",
    "        print(f\"accuracy = {conf_mat.diagonal().sum() / conf_mat.sum()}\\n\")\n",
    "        \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4f5f88a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for authors trump and biden, n = 2\n",
      "confusion matrix:\n",
      "[[  8  92   0]\n",
      " [  0 100   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.54\n",
      "\n",
      "results for authors trump and biden, n = 3\n",
      "confusion matrix:\n",
      "[[  3  97   0]\n",
      " [  0 100   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.515\n",
      "\n",
      "results for authors trump and biden, n = 4\n",
      "confusion matrix:\n",
      "[[  0 100   0]\n",
      " [  0 100   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.5\n",
      "\n",
      "results for authors trump and biden, n = 5\n",
      "confusion matrix:\n",
      "[[  0 100   0]\n",
      " [  0 100   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.5\n",
      "\n",
      "results for authors obama and biden, n = 2\n",
      "confusion matrix:\n",
      "[[100   0   0]\n",
      " [ 78  22   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.61\n",
      "\n",
      "results for authors obama and biden, n = 3\n",
      "confusion matrix:\n",
      "[[100   0   0]\n",
      " [ 78  22   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.61\n",
      "\n",
      "results for authors obama and biden, n = 4\n",
      "confusion matrix:\n",
      "[[100   0   0]\n",
      " [ 78  22   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.61\n",
      "\n",
      "results for authors obama and biden, n = 5\n",
      "confusion matrix:\n",
      "[[100   0   0]\n",
      " [ 78  22   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_length = 5\n",
    "validate(context_length, TRUMP, data_train[TRUMP], data_test[TRUMP], BIDEN, data_train[BIDEN], data_test[BIDEN], classify_fn=classify)\n",
    "validate(context_length, OBAMA, data_train[OBAMA], data_test[OBAMA], BIDEN, data_train[BIDEN], data_test[BIDEN], classify_fn=classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e1fb7-c67b-4e44-87c7-488e704c5ac1",
   "metadata": {},
   "source": [
    "### Compute Perplexities\n",
    "\n",
    "4.1 Compute (and plot) the perplexities for each of the test tweets and models. Is picking the Model with minimum perplexity a better classifier than in 3.1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9bfe2154-d816-442e-8de8-3b836ab0ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_perplexity(n: int, tokens: list[str], n_gram_model1: NGramModel, n_gram_model2: NGramModel) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    Checks which of the two given datasets is more likely for the given Tweet.\n",
    "    If true is returned, the first one is more likely, otherwise the second.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    neg_m_log_perp1 = 0\n",
    "    neg_m_log_perp2 = 0\n",
    "    m = 0\n",
    "    for i in range(2, len(tokens) + 1):\n",
    "        n_gram = tuple(tokens[max(0, i - n) : i])\n",
    "        neg_m_log_perp1 += n_gram_model1.conditional(n_gram)\n",
    "        neg_m_log_perp2 += n_gram_model2.conditional(n_gram)\n",
    "        m += 1\n",
    "    perp1 = math.exp(- neg_m_log_perp1 / m)\n",
    "    perp2 = math.exp(- neg_m_log_perp2 / m)\n",
    "    return perp1 < perp2 if perp1 != perp2 else None\n",
    "        \n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8b3be177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for authors trump and biden, n = 2\n",
      "confusion matrix:\n",
      "[[ 72  28   0]\n",
      " [  0 100   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.86\n",
      "\n",
      "results for authors trump and biden, n = 3\n",
      "confusion matrix:\n",
      "[[ 29  71   0]\n",
      " [  0 100   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.645\n",
      "\n",
      "results for authors trump and biden, n = 4\n",
      "confusion matrix:\n",
      "[[ 28  72   0]\n",
      " [  0 100   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.64\n",
      "\n",
      "results for authors trump and biden, n = 5\n",
      "confusion matrix:\n",
      "[[ 28  72   0]\n",
      " [  0 100   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.64\n",
      "\n",
      "results for authors obama and biden, n = 2\n",
      "confusion matrix:\n",
      "[[100   0   0]\n",
      " [100   0   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.5\n",
      "\n",
      "results for authors obama and biden, n = 3\n",
      "confusion matrix:\n",
      "[[100   0   0]\n",
      " [100   0   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.5\n",
      "\n",
      "results for authors obama and biden, n = 4\n",
      "confusion matrix:\n",
      "[[100   0   0]\n",
      " [100   0   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.5\n",
      "\n",
      "results for authors obama and biden, n = 5\n",
      "confusion matrix:\n",
      "[[100   0   0]\n",
      " [100   0   0]\n",
      " [  0   0   0]]\n",
      "accuracy = 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_length = 5\n",
    "validate(context_length, TRUMP, data_train[TRUMP], data_test[TRUMP], BIDEN, data_train[BIDEN], data_test[BIDEN], classify_fn=classify_with_perplexity)\n",
    "validate(context_length, OBAMA, data_train[OBAMA], data_test[OBAMA], BIDEN, data_train[BIDEN], data_test[BIDEN], classify_fn=classify_with_perplexity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
