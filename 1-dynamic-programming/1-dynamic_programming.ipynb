{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51f3ab5-22c7-4ead-9169-494e12e73c1a",
   "metadata": {},
   "source": [
    "# Assignment 1: Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0361ad-79a6-4492-b080-ee8bcf8ca4de",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1) Edit Distances\n",
    "\n",
    "Implement the [Hamming](https://en.wikipedia.org/wiki/Hamming_distance) and [Levenshtein](https://en.wikipedia.org/wiki/Levenshtein_distance) (edit) distances and compute them for the for the following word pairs.\n",
    "It may help to compute them by hand first.\n",
    "\n",
    "<img src = \"./assets/97090.jpg\" width=\"33%\" /> <img src = \"./assets/97222.jpg\" width=\"33%\" /> <img src = \"./assets/97669.jpg\" width=\"33%\" />\n",
    "\n",
    "Aside from computing the distance (which is a scalar), do the backtrace and compute the edit transcript (and thus alignment).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b947e856-5284-4cf2-922f-c44268c365ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_PAIRS = [\n",
    "    (\"GCGTATGAGGCTAACGC\", \"GCTATGCGGCTATACGC\"),\n",
    "    (\"kühler schrank\", \"schüler krank\"),\n",
    "    (\"the longest\", \"longest day\"),\n",
    "    (\"nicht ausgeloggt\", \"licht ausgenockt\"),\n",
    "    (\"gurken schaben\", \"schurkengaben\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f504ef-3822-44fe-986f-88b4ca791017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming(s1: str, s2: str) -> int:\n",
    "    \"\"\"\n",
    "    Compute the hamming distance between two strings.\n",
    "\n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "\n",
    "    Returns the distance as int.\n",
    "    \"\"\"\n",
    "    # Hint: Think about how you can deal with unequal word lengths.\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    if len(s2) < len(s1):\n",
    "        s1, s2 = s2, s1\n",
    "    return sum(int(s2[i] != c) for i, c in enumerate(s1)) + len(s2) - len(s1)\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a59e5d-2bcc-40d6-b3b8-c24d886bc9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 10\n",
      "hamming('kühler schrank', 'schüler krank') = 13\n",
      "hamming('the longest', 'longest day') = 11\n",
      "hamming('nicht ausgeloggt', 'licht ausgenockt') = 4\n",
      "hamming('gurken schaben', 'schurkengaben') = 14\n"
     ]
    }
   ],
   "source": [
    "for wordpair in WORD_PAIRS:\n",
    "    dist = hamming(s1=wordpair[0], s2=wordpair[1])\n",
    "    print(\"hamming('{}', '{}') = {}\".format(\n",
    "        wordpair[0], wordpair[1], dist\n",
    "    ))\n",
    "\n",
    "### EXPECTED\n",
    "# hamming('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 10\n",
    "# hamming('kühler schrank', 'schüler krank') = 13\n",
    "# hamming('the longest', 'longest day') = 11\n",
    "# hamming('nicht ausgeloggt', 'licht ausgenockt') = 4\n",
    "# hamming('gurken schaben', 'schurkengaben') = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9791159e-0511-44d1-9e39-481942835d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def levenshtein(s1: str, s2: str, cost={'m': 0, 's': 1, 'i': 1, 'd': 1}) -> tuple[int, str]:\n",
    "    \"\"\"\n",
    "    Compute the levenshtein (edit) distance between two strings.\n",
    "\n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "\n",
    "    Returns the distance as int and edit transcript as string.\n",
    "    \"\"\"\n",
    "    # Hint: The probably most intuitive approach is bottom-up.\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    D = np.zeros((len(s1) + 1, len(s2) + 1), dtype=np.int32)\n",
    "    paths = np.ndarray((len(s1), len(s2)), dtype=np.byte)\n",
    "    D[1:, 0] = np.arange(1, len(s1) + 1)\n",
    "    D[0, 1:] = np.arange(1, len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        for j, c2 in enumerate(s2):\n",
    "            cd = D[i, j+1] + cost[\"d\"]\n",
    "            ci = D[i+1, j] + cost[\"i\"]\n",
    "            D[i+1, j+1] = D[i, j]\n",
    "            if c1 != c2:\n",
    "                D[i+1, j+1] += cost[\"s\"]\n",
    "                op = \"s\"\n",
    "            else:\n",
    "                D[i+1, j+1] += cost[\"m\"]\n",
    "                op = \"m\"\n",
    "            if cd < D[i+1, j+1]:\n",
    "                D[i+1, j+1] = cd\n",
    "                op = \"d\"\n",
    "            if ci <= D[i+1, j+1]:\n",
    "                D[i+1, j+1] = ci\n",
    "                op = \"i\"\n",
    "            paths[i, j] = ord(op)\n",
    "    i = len(s1) - 1\n",
    "    j = len(s2) - 1\n",
    "    path = \"\"\n",
    "    while i != -1 and j != -1:\n",
    "        op = chr(paths[i, j])\n",
    "        path = op + path\n",
    "        if op != \"i\":\n",
    "            i -= 1\n",
    "        if op != \"d\":\n",
    "            j -= 1\n",
    "    path = \"d\" * (i + 1) + \"i\" * (j + 1) + path\n",
    "    return D[-1, -1], path\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b794add6-0ee0-4a64-a79f-4b0e68d3a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levenshtein('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 3 (mmdmmmmsmmmmmimmmm)\n",
      "levenshtein('kühler schrank', 'schüler krank') = 6 (ssmimmmmddsmmmm)\n",
      "levenshtein('the longest', 'longest day') = 8 (ddddmmmmmmmiiii)\n",
      "levenshtein('nicht ausgeloggt', 'licht ausgenockt') = 4 (smmmmmmmmmmsmssm)\n",
      "levenshtein('gurken schaben', 'schurkengaben') = 7 (siimmmmmdddsmmmm)\n"
     ]
    }
   ],
   "source": [
    "for wordpair in WORD_PAIRS:\n",
    "    dist, transcript = levenshtein(s1=wordpair[0], s2=wordpair[1])\n",
    "    print(\"levenshtein('{}', '{}') = {} ({})\".format(\n",
    "        wordpair[0], wordpair[1], dist, transcript\n",
    "    ))\n",
    "\n",
    "### EXPECTED\n",
    "# levenshtein('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 3 (mmdmmmmsmmmmmimmmm)\n",
    "# levenshtein('kühler schrank', 'schüler krank') = 6 (ssmimmmmsddmmmm)\n",
    "# levenshtein('the longest', 'longest day') = 8 (ddddmmmmmmmiiii)\n",
    "# levenshtein('nicht ausgeloggt', 'licht ausgenockt') = 4 (smmmmmmmmmmsmssm)\n",
    "# levenshtein('gurken schaben', 'schurkengaben') = 7 (siimmmmmsdddmmmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84084e8a-f48d-45a6-8f8d-199981dc0aa7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2) Basic Spelling Correction using Edit Distance\n",
    "\n",
    "For spelling correction, we will use prior knowledge, to put _some_ learning into our system.\n",
    "\n",
    "The underlying idea is the _Noisy Channel Model_, that is: The user _intends_ to write a word `w`, but through some noise in the process, happens to type the word `x`.\n",
    "\n",
    "The correct word $\\hat{w}$ is that word, that is a valid candidate and has the highest probability:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\DeclareMathOperator*{\\argmax}{argmax}\n",
    "\\hat{w} & = & \\argmax_{w \\in V} P(w | x) \\\\\n",
    "        & = & \\argmax_{w \\in V} \\frac{P(x|w) P(w)}{P(x)} \\\\\n",
    "        & = & \\argmax_{w \\in V} P(x|w) P(w)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "1. The candidates $V$ can be obtained from a _vocabulary_.\n",
    "2. The probability $P(w)$ of a word $w$ can be _learned (counted) from data_.\n",
    "3. The probability $P(x|w)$ is more complicated... It could be learned from data, but we could also use a _heuristic_ that relates to the edit distance, e.g. rank by distance.\n",
    "\n",
    "You may use [Peter Norvig's count_1w.txt](http://norvig.com/ngrams/) file, [local mirror](res/count_1w.tar.bz2).\n",
    "Note that it may help to restrict to the first 10k words to get started.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7190fb5-93c5-456b-835b-32a73d0f3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = [\n",
    "    \"pirates\",    # in-voc\n",
    "    \"pirutes\",    # pirates?\n",
    "    \"continoisly\",  # continuosly?\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce0ead32-59de-42c4-b488-a56001931fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "\n",
    "### TODO: Prepare the vocabulary\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "WORDS_URL = \"http://norvig.com/ngrams/count_1w.txt\"\n",
    "WORDS_FILE_PATH = \"data/count_1w.txt\"\n",
    "\n",
    "if not os.path.exists(WORDS_FILE_PATH):\n",
    "    text = requests.get(WORDS_URL).text\n",
    "    with open(WORDS_FILE_PATH, \"w\") as fp:\n",
    "        fp.write(text)\n",
    "else:\n",
    "    with open(WORDS_FILE_PATH) as fp:\n",
    "        text = fp.read()\n",
    "\n",
    "V = []\n",
    "counts = []\n",
    "total = 0\n",
    "for line in text.split(\"\\n\"):\n",
    "    match = re.match(r\"^(\\w+)\\s+(\\d+)$\", line)\n",
    "    if match is not None:\n",
    "        V.append(match.group(1))\n",
    "        count = int(match.group(2))\n",
    "        counts.append(count)\n",
    "        total += count\n",
    "P = { w: counts[i] / total for i, w in enumerate(V) }\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f88150c8-3d00-483e-8682-1f6720d2a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "import math\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "# assumption: typos are poisson distributed with 1 typo per 200 characters on average\n",
    "\n",
    "@cache\n",
    "def fac(x: int) -> int:\n",
    "    assert x >= 0\n",
    "    if x < 2:\n",
    "        return 1\n",
    "    return fac(x - 1) * x\n",
    "\n",
    "# Stirling's formula for factorial approximateion\n",
    "def fac_approx(x: int) -> float:\n",
    "    if x <= 20:\n",
    "        return fac(x)\n",
    "    return math.sqrt(2 * math.pi * x) * (x / math.e) ** x\n",
    "\n",
    "def poisson(k: int, l: float) -> float:\n",
    "    return l ** k / (fac_approx(k) * math.e ** l)\n",
    "\n",
    "TYPO_PER_CHAR = 0.005\n",
    "MAX_TYPOS_PER_CHAR = 0.5\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "def _dists_probs(args: tuple[Callable[[str, str], tuple[int, str]], str, str, float]) -> tuple[int, float]:\n",
    "    dist_fn, w, w_, prior = args\n",
    "    dist = dist_fn(w, w_)[0]\n",
    "    if dist >= MAX_TYPOS_PER_CHAR * len(w):\n",
    "        return dist, 0\n",
    "    prob = prior * poisson(dist, TYPO_PER_CHAR)\n",
    "    return dist, prob\n",
    "\n",
    "def suggest(w: str, dist_fn, max_cand=5) -> Sequence[tuple[str, int, float]]:\n",
    "    \"\"\"\n",
    "    Compute suggestions for spelling correction using edit distance.\n",
    "    \n",
    "    Arguments:\n",
    "    w: Word in question.\n",
    "    dist_fn: Distance function to use (e.g. levenshtein).\n",
    "    max_cand: Maximum number of suggestions.\n",
    "\n",
    "    Returns a list of tuples (word, dist, score) sorted by score and distance.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    with ProcessPoolExecutor() as exec:\n",
    "        dists_probs_ll = []\n",
    "        # batched processing required due to limitations of ProcessPoolExecutor\n",
    "        for i in range(math.ceil(len(V) / BATCH_SIZE)):\n",
    "            k = i * BATCH_SIZE\n",
    "            dists_probs_ll.append(list(exec.map(\n",
    "                _dists_probs,\n",
    "                ((dist_fn, w_, w, P[w_]) for w_ in V[k:k+BATCH_SIZE])\n",
    "            )))\n",
    "    candidates: list[tuple[str, int, float]] = [(\"\", 0, 0) for _ in range(max_cand)]\n",
    "    for i, (dist, prob) in enumerate((x for l in dists_probs_ll for x in l)):\n",
    "        j = max_cand - 1\n",
    "        if candidates[j][2] < prob:\n",
    "            while j > 0 and candidates[j - 1][2] < prob:\n",
    "                candidates[j] = candidates[j-1]\n",
    "                j -= 1\n",
    "            w_ = V[i]\n",
    "            candidates[j] = w_, dist, prob\n",
    "    i = max_cand\n",
    "    while i > 0 and candidates[i - 1][2] == 0:\n",
    "        i -= 1\n",
    "    return candidates[:i]\n",
    "\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5490ca-969c-4a93-aaf0-8cdb3433ff6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pirates [('pirates', 0, 1.105023539179934e-05), ('pirate', 1, 3.644597024494112e-08), ('pilates', 1, 2.0433874060751604e-08)]\n",
      "pirutes [('pirates', 1, 5.52511769589967e-08), ('minutes', 2, 2.0353310511005172e-09), ('viruses', 2, 1.8581852022600007e-10)]\n",
      "continoisly [('continously', 1, 7.295047817732711e-10), ('continuously', 2, 1.1864872327588812e-10), ('continuosly', 2, 5.101534083210598e-13)]\n"
     ]
    }
   ],
   "source": [
    "# How does your suggest function behave with levenshtein distance?\n",
    "\n",
    "for word in EXAMPLES:\n",
    "    suggestions = suggest(w=word, dist_fn=levenshtein, max_cand=3)\n",
    "    print(\"{} {}\".format(word, suggestions))\n",
    "\n",
    "### EXPECTED\n",
    "### Notice: your scores may vary!\n",
    "# pirates [('pirates', 0, -11.408058827802126)]\n",
    "# pirutes [('pirates', 1, -11.408058827802126), ('minutes', 2, -8.717825438953103), ('viruses', 2, -11.111468702571859)]\n",
    "# continoisly [('continously', 1, -15.735337826575178), ('continuously', 2, -11.560071979871001), ('continuosly', 2, -17.009283000138204)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa2e00-a1dd-46e5-90c0-2f3eea3cb031",
   "metadata": {},
   "source": [
    "### Food for Thought\n",
    "\n",
    "- How would you modify the implementation so that it works fast for large lexica (eg. the full file above)?\n",
    "- How would you modify the implementation so that it works \"while typing\" instead of at the end of a word?\n",
    "- How do you handle unknown/new words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a183c2b3-7cee-420e-bb08-5748dbfed5dc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 3) Needleman-Wunsch: Keyboard-aware Auto-Correct\n",
    "\n",
    "In the parts 1 and 2 above, we applied uniform cost to all substitutions.\n",
    "This does not really make sense if you look at a keyboard: the QWERTY layout will favor certain substitutions (eg. _a_ and _s_), while others are fairly unlikely (eg. _a_ and _k_).\n",
    "\n",
    "Implement the [Needleman-Wunsch algorithm](https://en.wikipedia.org/wiki/Needleman–Wunsch_algorithm) which is very similar to the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance), however it doesn't _minimize the cost_ but _maximizes the similarity_.\n",
    "For a good measure of similarity, implement a metric that computes a meaningful weight for a given character substitution.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23709626-6af8-41ae-b713-f0d8c7b117e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as la\n",
    "\n",
    "KEY_COORDINATES = {\n",
    "    \"q\": np.array([0, 0]),\n",
    "    \"w\": np.array([1, 0]),\n",
    "    \"e\": np.array([2, 0]),\n",
    "    \"r\": np.array([3, 0]),\n",
    "    \"t\": np.array([4, 0]),\n",
    "    \"y\": np.array([5, 0]),\n",
    "    \"u\": np.array([6, 0]),\n",
    "    \"i\": np.array([7, 0]),\n",
    "    \"o\": np.array([8, 0]),\n",
    "    \"p\": np.array([9, 0]),\n",
    "    \"a\": np.array([0.33, 1]),\n",
    "    \"s\": np.array([1.33, 1]),\n",
    "    \"d\": np.array([2.33, 1]),\n",
    "    \"f\": np.array([3.33, 1]),\n",
    "    \"g\": np.array([4.33, 1]),\n",
    "    \"h\": np.array([5.33, 1]),\n",
    "    \"j\": np.array([6.33, 1]),\n",
    "    \"k\": np.array([7.33, 1]),\n",
    "    \"l\": np.array([8.33, 1]),\n",
    "    \"z\": np.array([0.67, 2]),\n",
    "    \"x\": np.array([1.67, 2]),\n",
    "    \"c\": np.array([2.67, 2]),\n",
    "    \"v\": np.array([3.67, 2]),\n",
    "    \"b\": np.array([4.67, 2]),\n",
    "    \"n\": np.array([5.67, 2]),\n",
    "    \"m\": np.array([6.67, 2])    \n",
    "}\n",
    "\n",
    "def keyboardsim(s1: str, s2: str) -> float:\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    s1 = s1.lower()\n",
    "    s2 = s2.lower()\n",
    "    assert s1 in KEY_COORDINATES\n",
    "    assert s2 in KEY_COORDINATES\n",
    "    return (1 / (1 + la.norm(KEY_COORDINATES[s2] - KEY_COORDINATES[s1]))).item()\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def nw(s1: str, s2: str, d: float, sim_fn) -> float:\n",
    "    \"\"\"\n",
    "    Apply needleman-wunsch algorithm.\n",
    "    \n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "    d: Gap penalty score.\n",
    "    sim_fn: Similarity function to use.\n",
    "\n",
    "    Returns the score as float.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    D = np.zeros((len(s1) + 1, len(s2) + 1))\n",
    "    D[1:, 0] = np.arange(1, len(s1) + 1) * d\n",
    "    D[0, 1:] = np.arange(1, len(s2) + 1) * d\n",
    "    for i, c1 in enumerate(s1):\n",
    "        for j, c2 in enumerate(s2):\n",
    "            D[i+1, j+1] = max(\n",
    "                D[i, j] + keyboardsim(c1, c2),\n",
    "                D[i, j+1] + d,\n",
    "                D[i+1, j] + d\n",
    "            )\n",
    "    return D[-1, -1]\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def nw_based_dist(s1: str, s2: str) -> tuple[int, str]:\n",
    "    \"\"\"\n",
    "    Compute the needleman-wunsch distance between two strings.\n",
    "    \n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "    \n",
    "    Returns the distance as int and <unsupported> string.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    return round(len(s1) - nw(s1, s2, -0.5, keyboardsim)), \"<unsuppoorted>\"\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f510005-f578-4afa-99a3-9a389fd86069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pirates [('pirates', 0, 1.105023539179934e-05), ('pirate', 0, 7.289194048988224e-06), ('rates', 1, 1.1596682843072494e-06)]\n",
      "pirutes [('pirates', 1, 5.52511769589967e-08), ('pirate', 1, 3.644597024494112e-08), ('price', 2, 1.0608924376418283e-08)]\n",
      "continoisly [('continously', 0, 1.4590095635465423e-07), ('continuing', 2, 5.377825200587693e-10), ('continues', 2, 5.076294992502114e-10)]\n"
     ]
    }
   ],
   "source": [
    "# How does your suggest function behave with nw and a keyboard-aware similarity?\n",
    "\n",
    "for word in EXAMPLES:\n",
    "    suggestions = suggest(w=word, dist_fn=nw_based_dist, max_cand=3)\n",
    "    print(\"{} {}\".format(word, suggestions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf63b759-ba2d-4ad1-9011-f0067e968688",
   "metadata": {},
   "source": [
    "### Food for Thought\n",
    "\n",
    "- What could be better heuristics for similarity resp. cost of substitution than the one above?\n",
    "- What about capitalization, punctiation and special characters?\n",
    "- What about swipe-to-type?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
